setwd("C:/Past Education/SantaClara/MKTG2505/HW2")
library("tidyverse")
library("readxl")
library("janitor")
library("dendextend")
library("factoextra")
library("ggplot2")
library("caret")
library("Metrics")
mydata = read_excel('Rideshare.xlsx')
mydata<-clean_names(mydata)
# check missing value and type of the data
colSums(is.na(mydata))
str(mydata)
# the distribution of Price
ggplot(mydata, aes(x=price))+geom_histogram(bins = 15, fill = "grey") +
labs(title = "Histogram of Price", x = "Price", y = "Frequency")
# EDA for datetime data:
# Convert the 'month' column to a factor with custom order
mydata$month <- factor(mydata$month, levels = c("8", "9", "10", "11", "12"))
ggplot(mydata, aes(x=month))+geom_bar(fill = "grey") +
labs(title = "Histogram of Month", x = "Month", y = "Frequency")
# Convert the 'weekday' column to a factor with custom order
mydata$weekday <- factor(mydata$weekday, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))
# Create the ggplot with customized order
ggplot(mydata, aes(x = weekday)) +
geom_bar(fill = "grey") +
labs(title = "Histogram of weekday", x = "weekday", y = "Frequency")
# Transform hour into sine and cosine components for  Cyclical Features
mydata$hour_sin <- sin(2 * pi * mydata$hour / 24)
mydata$hour_cos <- cos(2 * pi * mydata$hour / 24)
ggplot(mydata,aes(x=hour_sin,y=price))+geom_point()
ggplot(mydata,aes(x=hour_cos,y=price))+geom_point()
ggplot(mydata,aes(x=hour,y=price))+geom_point()
ggplot(mydata,aes(x=hour))+geom_bar()
# time trend plot for each date
# Create a dummy variable
mydata$month_day <- paste0(mydata$month,"-",mydata$day)
mydata$month_day <- as.factor(mydata$month_day)
# Count the frequency of occurrences for each month-day
frequency_data <- data.frame(table(mydata$month_day))
colnames(frequency_data)<-c("month_day","month_day_freq")
# Create ggplot for frequency over time
ggplot(frequency_data, aes(x = month_day, y = month_day_freq,group = 1)) +
geom_line() +
labs(title = "Frequency Over Time", x = "Month-Day", y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability
# Merge aggregated features back into the original data
mydata <- left_join(mydata, frequency_data, by = "month_day")
# exam the difference of month_day_freq and month_day
summary(lm(price~month_day_freq,mydata))
summary(lm(price~month_day,mydata))
summary(lm(price~month_day_freq+month_day,mydata))
# the unique of pick out and drop off location
unique(mydata$source)
unique(mydata$destination)
mydata$route <- paste0(mydata$source,"-",mydata$destination)
unique(mydata$route)
mydata$route <- as.factor(mydata$route)
# boxplot of the price by different route
ggplot(mydata, aes(x = route, y = price,)) +
geom_boxplot() +
labs(title = "Boxplot of Price", x = "Route", y = "Price") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# boxplot of the distance by different route
ggplot(mydata, aes(x = route, y = distance)) +
geom_boxplot() +
labs(title = "Boxplot of Distance", x = "Route", y = "Distance") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
mydata_aggregated <- mydata %>%
group_by(route) %>%
summarise(avgRoute_distance = mean(distance))
# Merge aggregated features back into the original data
mydata <- left_join(mydata, mydata_aggregated, by = "route")
# exam the difference of avgRoute_distance and route
summary(lm(price~avgRoute_distance+distance,mydata))
summary(lm(price~route+distance,mydata))
# uber or lyft
ggplot(mydata,aes(x=rideshare))+geom_bar()
ggplot(mydata,aes(x=ride_category))+geom_bar()
mydata$rideshare <- as.factor(mydata$rideshare)
mydata$ride_category <- as.factor(mydata$ride_category)
# exam the rideshare
summary(lm(price~rideshare+ride_category,mydata))
# compare all the numerical feature with price
numerical_columns <- mydata %>% select_if(is.numeric)
numerical_columns<- numerical_columns[,-c(1,2)]
par(mfrow = c(3, 4))
for(i in 2:13){
plot(unlist(numerical_columns[,i]), numerical_columns$price,xlab = colnames(numerical_columns)[i])
}
plot( log(numerical_columns$distance), numerical_columns$price)
cor(numerical_columns)
# exam the numerical
summary(lm(price~cbind(distance,surge_multiplier),mydata))
# feature selection
model_data <- mydata %>%
select(-id, -date_time, -hour, -day, -month, -source, -destination,-month_day)
# stepwise
intercept<-lm(price~1,model_data)
all<-lm(price~ . ,model_data)
stepboth<-step(intercept,direction="both",scope=formula(all))
stepboth$anova
stepboth$terms
stepboth$anova
# nfold validation
set.seed(926)
trainfold<-trainControl(method="cv", number=10, savePredictions = TRUE)
modelfold<-train(price~distance+ ride_category+ month_day_freq+ surge_multiplier+ weekday+ rideshare
+ avgRoute_distance+ ozone+ weather+ temperature+ wind_gust+ humidity+ hour_sin+ hour_cos
, data= trainset, method="lm",trControl=trainfold)
sample_i<-sample.int(nrow(model_data), replace=FALSE,
size=0.80*nrow(model_data))
trainset<-model_data[sample_i,]
testset<-model_data[-sample_i,]
# nfold validation
set.seed(926)
trainfold<-trainControl(method="cv", number=10, savePredictions = TRUE)
modelfold<-train(price~distance+ ride_category+ month_day_freq+ surge_multiplier+ weekday+ rideshare
+ avgRoute_distance+ ozone+ weather+ temperature+ wind_gust+ humidity+ hour_sin+ hour_cos
, data= trainset, method="lm",trControl=trainfold)
summary(modelfold)
# view final model
modelfold$finalModel
modelfold$pred
# view prediction for each fold
modelfold$resample
# obtain predicted values in testset
pred<-predict(modelfold, testset)
mae(testset$price, pred)
mape(testset$price, pred)
# obtain predicted values in trainset and the error
mae(trainset$price, modelfold$pred)
# obtain predicted values in trainset and the error
mae(trainset$price, modelfold$pred)
mae(testset$price, pred)
mape(testset$price, pred)
modelfold$pred
# obtain predicted values in trainset and the error
pred<-predict(modelfold, trainset)
mae(trainset$price, pred)
mape(trainset$price, pred)
# obtain predicted values in testset and the error
pred<-predict(modelfold, testset)
mae(testset$price, pred)
mape(testset$price, pred)
summary(modelfold)
setwd("C:/Past Education/SantaClara/MKTG2505/HW2")
library("tidyverse")
library("readxl")
library("janitor")
library("dendextend")
library("factoextra")
library("ggplot2")
library("caret")
library("Metrics")
mydata = read_excel('Rideshare.xlsx')
mydata<-clean_names(mydata)
# check missing value and type of the data
colSums(is.na(mydata))
str(mydata)
summary(mydata)
# the distribution of Price
ggplot(mydata, aes(x=log(price)))+geom_histogram(bins = 15, fill = "grey") +
labs(title = "Histogram of Log Price", x = "Log Price", y = "Frequency")
sd(mydata$price)
# EDA for datetime data:
# Convert the 'month' column to a factor with custom order
mydata$month <- factor(mydata$month, levels = c("8", "9", "10", "11", "12"))
ggplot(mydata, aes(x=month))+geom_bar(fill = "grey") +
labs(title = "Histogram of Month", x = "Month", y = "Frequency")
# Convert the 'weekday' column to a factor with custom order
mydata$weekday <- factor(mydata$weekday, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))
# Create the ggplot with customized order
ggplot(mydata, aes(x = weekday)) +
geom_bar(fill = "grey") +
labs(title = "Histogram of weekday", x = "weekday", y = "Frequency")
# Transform hour into sine and cosine components for  Cyclical Features
mydata$hour_sin <- sin(2 * pi * mydata$hour / 24)
mydata$hour_cos <- cos(2 * pi * mydata$hour / 24)
ggplot(mydata,aes(x=hour_sin,y=price))+geom_point()
ggplot(mydata,aes(x=hour_cos,y=price))+geom_point()
ggplot(mydata,aes(x=hour,y=price))+geom_point()
ggplot(mydata,aes(x=hour))+geom_bar()
# time trend plot for each date
# Create a dummy variable
mydata$month_day <- paste0(mydata$month,"-",mydata$day)
mydata$month_day <- as.factor(mydata$month_day)
# Count the frequency of occurrences for each month-day
frequency_data <- data.frame(table(mydata$month_day))
colnames(frequency_data)<-c("month_day","month_day_freq")
month_day2<- format(mydata$date_time, "%m-%d")
frequency_data2 <- data.frame(table(month_day2))
# Create ggplot for frequency over time
ggplot(frequency_data2, aes(x = month_day2 , y = Freq,group = 1)) +
geom_line() +
labs(title = "Frequency Over Time", x = "Month-Day", y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability
# Merge aggregated features back into the original data
mydata <- left_join(mydata, frequency_data, by = "month_day")
# exam the difference of month_day_freq and month_day
summary(lm(price~month_day_freq,mydata))
summary(lm(price~month_day,mydata))
summary(lm(price~month_day_freq+month_day,mydata))
# the unique of pick out and drop off location
unique(mydata$source)
unique(mydata$destination)
mydata$route <- paste0(mydata$source,"-",mydata$destination)
unique(mydata$route)
mydata$route <- as.factor(mydata$route)
# boxplot of the price by different route
ggplot(mydata, aes(x = route, y = price,)) +
geom_boxplot() +
labs(title = "Boxplot of Price", x = "Route", y = "Price") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# boxplot of the distance by different route
ggplot(mydata, aes(x = route, y = distance)) +
geom_boxplot() +
labs(title = "Boxplot of Distance", x = "Route", y = "Distance") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, hjust = 1))
mydata_aggregated <- mydata %>%
group_by(route) %>%
summarise(
avgRoute_distance = mean(distance),
sdRoute_distance = sd(distance),
numRoute = n()
)
# Merge aggregated features back into the original data
mydata <- left_join(mydata, mydata_aggregated, by = "route")
# bargraph of the average distance for each route
ggplot(mydata, aes(x = route, y = distance)) +
stat_summary(fun = "mean", geom = "bar", fill = "skyblue", color = "black") +
labs(title = "The Average of each Route", x = "Route", y = "Average Distance") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# bargraph of the freq for each route
ggplot(mydata_aggregated, aes(x = route, y = numRoute)) +
geom_col()+
labs(title = "The freq of each Route", x = "Route", y = "Frequency") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# exam the difference of avgRoute_distance and route
summary(lm(price~avgRoute_distance+distance,mydata))
summary(lm(price~route+distance,mydata))
# uber or lyft
ggplot(mydata,aes(x=rideshare))+geom_bar()
ggplot(mydata,aes(x=ride_category))+geom_bar()
mydata$rideshare <- as.factor(mydata$rideshare)
mydata$ride_category <- as.factor(mydata$ride_category)
# exam the rideshare
summary(lm(price~rideshare+ride_category,mydata))
# compare all the numerical feature with price
numerical_columns <- mydata %>% select_if(is.numeric)
numerical_columns<- numerical_columns[,-c(1,2)]
par(mfrow = c(3, 4))
for(i in 2:13){
plot(unlist(numerical_columns[,i]), numerical_columns$price,xlab = colnames(numerical_columns)[i])
}
plot( log(numerical_columns$distance), numerical_columns$price)
cor(numerical_columns)
# exam the numerical
summary(lm(price~cbind(distance,surge_multiplier),mydata))
# feature selection
model_data <- mydata %>%
select(-id, -date_time, -hour, -day, -month, -route,-source, -destination,-month_day)
# stepwise
intercept<-lm(log(price)~1,model_data)
all<-lm(log(price)~ . ,model_data)
stepboth<-step(intercept,direction="both",scope=formula(all))
stepboth$anova
# training
# Standardize numeric columns (excluding 'price')
mydata_scaled <- model_data %>%
mutate(across(where(is.numeric), scale))
mydata_scaled$price<-mydata$price
sample_i<-sample.int(nrow(mydata_scaled), replace=FALSE,
size=0.80*nrow(mydata_scaled))
trainset<-mydata_scaled[sample_i,]
testset<-mydata_scaled[-sample_i,]
# nfold validation
set.seed(926)
trainfold<-trainControl(method="cv", number=10, savePredictions = TRUE)
modelfold<-train(log(price)~ride_category + distance + month_day_freq + weekday +
surge_multiplier + ozone + weather + avgRoute_distance.x +
temperature + rideshare + wind_gust + hour_cos + hour_sin +
humidity,
data= trainset, method="lm",trControl=trainfold)
modelfold<-train(log(price)~ride_category + distance + month_day_freq + weekday +
surge_multiplier + ozone + weather + avgRoute_distance +
temperature + rideshare + wind_gust + hour_cos + hour_sin +
humidity,
data= trainset, method="lm",trControl=trainfold)
summary(modelfold)
# view final model
final_model = modelfold$finalModel
# obtain predicted values in trainset and the error
pred<-predict(modelfold, trainset)
mae(trainset$price, exp(pred))
mape(trainset$price, exp(pred))
# obtain predicted values in testset and the error
pred<-predict(modelfold, testset)
mae(testset$price, exp(pred))
mape(testset$price, exp(pred))
summary(modelfold)
# view final model
final_model = modelfold$finalModel
# view prediction for each fold
modelfold$resample
# normal proablility plot
qqnorm(final_model$residuals)
# normal proablility plot
qqnorm(final_model$residuals)
qqline(final_model$residuals)
# obtain predicted values in trainset and the error
pred<-predict(modelfold, trainset)
mae(trainset$price, exp(pred))
mape(trainset$price, exp(pred))
# obtain predicted values in testset and the error
pred<-predict(modelfold, testset)
mae(testset$price, exp(pred))
mape(testset$price, exp(pred))
# normal proablility plot
qqnorm(final_model$residuals)
qqline(final_model$residuals)
mae(trainset$price, exp(pred))
mape(trainset$price, exp(pred))
mae(trainset$price, exp(pred))
# obtain predicted values in trainset and the error
pred<-predict(modelfold, trainset)
mae(trainset$price, exp(pred))
mape(trainset$price, exp(pred))
# obtain predicted values in testset and the error
pred<-predict(modelfold, testset)
mae(testset$price, exp(pred))
mape(testset$price, exp(pred))
# uber or lyft
ggplot(mydata,aes(x=rideshare,y=price))+geom_col()
